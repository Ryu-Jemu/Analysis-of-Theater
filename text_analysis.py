import requests
import json
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from konlpy.tag import Okt
from collections import Counter
import csv

# API authentication credentials
client_id = "_____"  
client_secret = "_____"  

# API endpoint for Naver Blog Search
url = "______" 

# Search keyword
query = "ë©”ê°€ë°•ìŠ¤" 

# Request parameters
params = {
    "query": query,  
    "display": 100,  # Number of results per request (max: 100)
    "start": 1,  
    "sort": "sim"  
}

# Request headers including authentication
headers = {
    "X-Naver-Client-Id": client_id,  
    "X-Naver-Client-Secret": client_secret  
}

# Make the API request
response = requests.get(url, headers=headers, params=params)

plt.rcParams['font.family'] = 'Malgun Gothic'  # For Windows users

# Check if the API call is successful
if response.status_code == 200:  
    data = response.json()  

    
    text_data = []
    for item in data["items"]:
        text_data.append(item["title"])  
        text_data.append(item["description"])  

    text = " ".join(text_data)
    okt = Okt()  
    tokens = okt.nouns(text)  

    # Remove stopwords (words that are not useful for analysis)
    stopwords = [
    "CGV", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤", "ì˜í™”", "ìƒì˜ê´€", "ê·¹ìž¥", "ì¢Œì„", 
    "ì˜ˆë§¤", "ìƒì˜", "ì‹œê°„í‘œ", "ì˜í™”ê´€", "ê³ ê°ì„¼í„°", "ë¸”ë¡œê·¸", "í›„ê¸°", "í¬ìŠ¤íŒ…",
    "ë§í¬", "ì‚¬ì§„", "ê³µìœ ", "ìž‘ì„±", "ì¶”ì²œ", "ì¡°íšŒ", "ëŒ“ê¸€", "ì¢‹ì•„ìš”", "ëŒ€í•´", 
    "ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì™€", "ê³¼", "ë„", "ì—", "ì—ì„œ", 
    "ë³´ë‹¤", "ìœ¼ë¡œ", "ë˜ëŠ”", "ê·¸ë¦¬ê³ ", "í•´ì„œ", "ê·¸ëŸ¬ë‚˜", "ë„ˆë¬´", "ì •ë§", "ë§Žì´", 
    "ì•„ì£¼", "ê·¸ëƒ¥", "ê·¸ëž˜ì„œ", "ì´ì œ", "ë‹¤ì‹œ", "ì´ë ‡ê²Œ", "ì €ë ‡ê²Œ", "ðŸ˜€", "ðŸ˜¢", "â¤ï¸",
    "!", "?", ".", ",", "/", "@", "#", "%", "2024", "11ì›”", "2023ë…„", "ì •ë³´","ëŒ€í•œ"
    ]

    filtered_tokens = [token for token in tokens if token not in stopwords and len(token) > 1]
    word_counts = Counter(filtered_tokens)

    # **Save keywords to a CSV file**
    csv_file_path = "extracted_keywords.csv"  
    with open(csv_file_path, mode="w", newline="", encoding="utf-8-sig") as file:
        writer = csv.writer(file)  
        writer.writerows(word_counts.items()) 
    print(f"Keywords have been saved to '{csv_file_path}'.")

    # **Generate a word cloud**
    font_path = "C:/Windows/Fonts/malgun.ttf"  # Path to Korean font for Windows
    wordcloud = WordCloud(
        font_path=font_path,  
        background_color="white",  
        width=800,  
        height=600,  
        max_words=50  # Limit the word cloud to the top 50 words
    ).generate_from_frequencies(word_counts)  
    # Visualize the word cloud
    plt.figure(figsize=(10, 8))  
    plt.imshow(wordcloud, interpolation="bilinear")  
    plt.axis("off")  
    plt.title(f"'{query}' Related Word Cloud", fontsize=15)  
    plt.show()  
else:
    # Print error details if the API call fails
    print(f"Error Code: {response.status_code}") 
    print(f"Error Message: {response.text}")  